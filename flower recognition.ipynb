{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"t2uHKH27dM0-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"qcaLCky8fAEu"},"source":["# ** let’s import the necessary Python libraries to get started with the task of Flower Recognition with Python:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WaVjuxEPdA4X"},"outputs":[],"source":["import os\n","import cv2\n","import numpy as np\n","\n","#Encoding and Split data into Train/Test Sets\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","\n","#Tensorflow Keras CNN Model\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n","\n","#Plot Images\n","import matplotlib.pyplot as plt\n","\n","\n","folder_dir = '/content/drive/MyDrive/ml project/flowers'"]},{"cell_type":"markdown","metadata":{"id":"YknMa5E-fIA2"},"source":["# **Read each image in the data and create a label for each with the name of the folder:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qr9sfb4bdfBP"},"outputs":[],"source":["data = []\n","label = []\n","\n","SIZE = 128 #Crop the image to 128x128\n","\n","for folder in os.listdir(folder_dir):\n","    for file in os.listdir(os.path.join(folder_dir, folder)):\n","        if file.endswith(\"jpg\"):\n","            label.append(folder)\n","            img = cv2.imread(os.path.join(folder_dir, folder, file))\n","            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","            im = cv2.resize(img_rgb, (SIZE,SIZE))\n","            data.append(im)\n","        else:\n","            continue"]},{"cell_type":"markdown","metadata":{"id":"keHItORzfN5_"},"source":["# **convert the data into numerical values:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4uWje8GWdfX2"},"outputs":[],"source":["data_arr = np.array(data)\n","label_arr = np.array(label)"]},{"cell_type":"markdown","metadata":{"id":"tCfrupFlfRfG"},"source":["# **use the Label encoder and normalize the data:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hd-TM_-sdfjW"},"outputs":[],"source":["encoder = LabelEncoder()\n","y = encoder.fit_transform(label_arr)\n","y = to_categorical(y,5)\n","X = data_arr/255"]},{"cell_type":"markdown","metadata":{"id":"H7US2hNlfVp2"},"source":["# **split the dataset into 80% training and 20% test sets:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C9ZCsmNFdftv"},"outputs":[],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)"]},{"cell_type":"markdown","metadata":{"id":"YkhivlJWfZqH"},"source":["# **let’s build a neural network model for the task of Flower Recognition:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bTdnItA1duXZ"},"outputs":[],"source":["model = Sequential()\n","model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu', input_shape = (SIZE,SIZE,3)))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n","model.add(MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dropout(rate=0.5))\n","model.add(Dense(5, activation = \"softmax\"))"]},{"cell_type":"markdown","metadata":{"id":"auXn4qXDfdk2"},"source":["# **create more training images to prevent overfitting:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IAgxctvQdueW"},"outputs":[],"source":["datagen = ImageDataGenerator(\n","        rotation_range=20,\n","        zoom_range = 0.20,\n","        width_shift_range=0.3,\n","        height_shift_range=0.3,\n","        horizontal_flip=True,\n","        vertical_flip=True)\n","\n","datagen.fit(X_train)"]},{"cell_type":"markdown","metadata":{"id":"bosVv_Brfig2"},"source":["# **compile the neural network model:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"3nkYO9t4dujK","outputId":"664d4683-58b4-4afd-db3c-920ee6ea5ab5"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super(Adam, self).__init__(name, **kwargs)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  import sys\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/64\n","108/108 [==============================] - 810s 7s/step - loss: 1.5271 - accuracy: 0.3038 - val_loss: 1.3222 - val_accuracy: 0.4525\n","Epoch 2/64\n","108/108 [==============================] - 770s 7s/step - loss: 1.3341 - accuracy: 0.4266 - val_loss: 1.2152 - val_accuracy: 0.4919\n","Epoch 3/64\n","108/108 [==============================] - 773s 7s/step - loss: 1.2839 - accuracy: 0.4555 - val_loss: 1.1624 - val_accuracy: 0.5440\n","Epoch 4/64\n","108/108 [==============================] - 770s 7s/step - loss: 1.2336 - accuracy: 0.4923 - val_loss: 1.1347 - val_accuracy: 0.5347\n","Epoch 5/64\n","108/108 [==============================] - 764s 7s/step - loss: 1.1854 - accuracy: 0.5193 - val_loss: 1.0939 - val_accuracy: 0.5718\n","Epoch 6/64\n"," 93/108 [========================>.....] - ETA: 1:39 - loss: 1.1333 - accuracy: 0.5647"]}],"source":["model.compile(optimizer=Adam(lr=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])\n","batch_size=32\n","epochs=64\n","history = model.fit_generator(datagen.flow(X_train,y_train, batch_size=batch_size),\n","                              epochs = epochs,\n","                              validation_data = (X_test,y_test),\n","                              verbose = 1)"]},{"cell_type":"markdown","metadata":{"id":"6lNRQXG2fop-"},"source":["# **let the model if it recognize flowers properly:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Df_i5Cedunm"},"outputs":[],"source":["categories = np.sort(os.listdir(folder_dir))\n","fig, ax = plt.subplots(6,6, figsize=(25, 40))\n","\n","for i in range(6):\n","    for j in range(6):\n","        k = int(np.random.random_sample() * len(X_test))\n","        if(categories[np.argmax(y_test[k])] == categories[np.argmax(model.predict(X_test)[k])]):\n","            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='green')\n","            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='green')\n","            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')\n","        else:\n","            ax[i,j].set_title(\"TRUE: \" + categories[np.argmax(y_test[k])], color='red')\n","            ax[i,j].set_xlabel(\"PREDICTED: \" + categories[np.argmax(model.predict(X_test)[k])], color='red')\n","            ax[i,j].imshow(np.array(X_test)[k].reshape(SIZE, SIZE, 3), cmap='gray')"]}],"metadata":{"colab":{"name":"flower recognition.ipynb","provenance":[],"authorship_tag":"ABX9TyMA6OzMBW085HThjHXbBZ7S"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}